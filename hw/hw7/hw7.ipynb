{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 7: Word embeddings and topic modeling \n",
    "**Due date: [Apr 2, 11:59pm](https://github.com/UBC-CS/cpsc330-2023W2?tab=readme-ov-file#deliverable-due-dates-tentative).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from hashlib import sha1\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Submission instructions\n",
    "<hr>\n",
    "\n",
    "_points: 2_\n",
    "\n",
    "You will receive marks for correctly submitting this assignment. To submit this assignment, follow the instructions below:\n",
    "\n",
    "- **You may work on this assignment in a group (group size <= 4) and submit your assignment as a group.** \n",
    "- Below are some instructions on working as a group.  \n",
    "    - The maximum group size is 4. \n",
    "    - You can choose your own group members. \n",
    "    - Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "    - Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "    - It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. [Here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members) are some instructions on adding group members in Gradescope.  \n",
    "- Be sure to follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2023W2/blob/main/docs/homework_instructions.md).\n",
    "- Upload the .ipynb file to PrairieLearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1:  Exploring pre-trained word embeddings <a name=\"1\"></a>\n",
    "<hr>\n",
    "\n",
    "In lecture 17, we talked about natural language processing (NLP). Using pre-trained word embeddings is very common in NLP. It has been shown that pre-trained word embeddings work well on a variety of text classification tasks. These embeddings are created by training a model like Word2Vec on a huge corpus of text such as a dump of Wikipedia or a dump of the web crawl. \n",
    "\n",
    "A number of pre-trained word embeddings are available out there. Some popular ones are: \n",
    "\n",
    "- [GloVe](https://nlp.stanford.edu/projects/glove/)\n",
    "    * trained using [the GloVe algorithm](https://nlp.stanford.edu/pubs/glove.pdf) \n",
    "    * published by Stanford University \n",
    "- [fastText pre-trained embeddings for 294 languages](https://fasttext.cc/docs/en/pretrained-vectors.html) \n",
    "    * trained using the fastText algorithm\n",
    "    * published by Facebook\n",
    "    \n",
    "In this exercise, you will be exploring GloVe Wikipedia pre-trained embeddings. The code below loads the word vectors trained on Wikipedia using an algorithm called Glove. You'll need `gensim` package in your cpsc330 conda environment to run the code below. \n",
    "\n",
    "```\n",
    "> conda activate cpsc330\n",
    "> conda install -c anaconda gensim\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.downloader\n",
    "\n",
    "print(list(gensim.downloader.info()[\"models\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# This will take a while to run when you run it for the first time.\n",
    "import gensim.downloader as api\n",
    "\n",
    "glove_wiki_vectors = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_wiki_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 400,000 word vectors in this pre-trained model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have GloVe Wiki vectors loaded in `glove_wiki_vectors`, let's explore the embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.1 Word similarity using pre-trained embeddings\n",
    "\n",
    "_Points:_ 2\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "- Come up with a list of 4 words of your choice and find similar words to these words in `glove_wiki_vectors` embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('garbage', 0.9249536991119385),\n",
       " ('rubbish', 0.8067941069602966),\n",
       " ('dump', 0.7270699143409729),\n",
       " ('pile', 0.7196474075317383),\n",
       " ('waste', 0.7033370137214661),\n",
       " ('piles', 0.6982601284980774),\n",
       " ('bins', 0.6639981269836426),\n",
       " ('recycling', 0.6520524621009827),\n",
       " ('cans', 0.6504139304161072),\n",
       " ('heap', 0.6450256705284119)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_wiki_vectors.most_similar(\"trash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('baskets', 0.7103695869445801),\n",
       " ('layup', 0.6246376633644104),\n",
       " ('ball', 0.6069576144218445),\n",
       " ('throws', 0.6052566766738892),\n",
       " ('3-pointer', 0.5942085981369019),\n",
       " ('dunk', 0.5935219526290894),\n",
       " ('clutch', 0.5659646987915039),\n",
       " ('fouled', 0.5471230149269104),\n",
       " ('3-point', 0.5469396114349365),\n",
       " ('rebound', 0.5314509272575378)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_wiki_vectors.most_similar(\"basket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sunny', 0.6617124676704407),\n",
       " ('warm', 0.5916898846626282),\n",
       " ('rain', 0.5708038806915283),\n",
       " ('chilly', 0.5552759170532227),\n",
       " ('sun', 0.5513474941253662),\n",
       " ('rainy', 0.5475090742111206),\n",
       " ('skies', 0.5463058948516846),\n",
       " ('warmth', 0.5366362929344177),\n",
       " ('cool', 0.5352686047554016),\n",
       " ('snow', 0.5339584350585938)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_wiki_vectors.most_similar(\"sunshine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yellow', 0.8597684502601624),\n",
       " ('blue', 0.8435065150260925),\n",
       " ('green', 0.8204779028892517),\n",
       " ('black', 0.7679567337036133),\n",
       " ('white', 0.7675364017486572),\n",
       " ('purple', 0.7657994627952576),\n",
       " ('pink', 0.7491969466209412),\n",
       " ('orange', 0.7140781283378601),\n",
       " ('dark', 0.699396014213562),\n",
       " ('gray', 0.6913918256759644)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_wiki_vectors.most_similar(\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Word similarity using pre-trained embeddings\n",
    "\n",
    "_Points:_ 2\n",
    "\n",
    "**Your tasks:**\n",
    "1. Calculate cosine similarity for the following word pairs (`word_pairs`) using the [`similarity`](https://radimrehurek.com/gensim/models/keyedvectors.html?highlight=similarity#gensim.models.keyedvectors.KeyedVectors.similarity) method of `glove_wiki_vectors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pairs = [\n",
    "    (\"coast\", \"shore\"),\n",
    "    (\"clothes\", \"closet\"),\n",
    "    (\"old\", \"new\"),\n",
    "    (\"smart\", \"intelligent\"),\n",
    "    (\"dog\", \"cat\"),\n",
    "    (\"tree\", \"lawyer\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim(word_pair):\n",
    "    return glove_wiki_vectors.similarity(word_pair[0], word_pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coast_shore_similarity =  0.7000272\n",
      "clothes_closet_similarity =  0.546276\n",
      "old_new_similarity =  0.6432488\n",
      "smart_intelligent_similarity =  0.7552732\n",
      "dog_cat_similarity =  0.8798075\n",
      "tree_lawyer_similarity =  0.076719455\n"
     ]
    }
   ],
   "source": [
    "coast_shore_similarity = get_sim(word_pairs[0])\n",
    "clothes_closet_similarity = get_sim(word_pairs[1])\n",
    "old_new_similarity = get_sim(word_pairs[2])\n",
    "smart_intelligent_similarity = get_sim(word_pairs[3])\n",
    "dog_cat_similarity = get_sim(word_pairs[4])\n",
    "tree_lawyer_similarity = get_sim(word_pairs[5])\n",
    "\n",
    "print(\"coast_shore_similarity = \", coast_shore_similarity)\n",
    "print(\"clothes_closet_similarity = \", clothes_closet_similarity)\n",
    "print(\"old_new_similarity = \" , old_new_similarity)\n",
    "print(\"smart_intelligent_similarity = \" , smart_intelligent_similarity)\n",
    "print(\"dog_cat_similarity = \" , dog_cat_similarity)\n",
    "print(\"tree_lawyer_similarity = \" , tree_lawyer_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.3 Stereotypes and biases in embeddings\n",
    "\n",
    "_Points:_ 6\n",
    "\n",
    "Word vectors contain lots of useful information. But they also contain stereotypes and biases of the texts they were trained on. In the lecture, we saw an example of gender bias in Google News word embeddings. Here we are using pre-trained embeddings trained on Wikipedia data. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Explore whether there are any worrisome biases or stereotypes present in these embeddings or not by trying out at least 4 examples. You can use the following two methods or other methods of your choice to explore what kind of stereotypes and biases are encoded in these embeddings. \n",
    "    - the `analogy` function below which gives word analogies (an example shown below)\n",
    "    - [similarity](https://radimrehurek.com/gensim/models/keyedvectors.html?highlight=similarity#gensim.models.keyedvectors.KeyedVectors.similarity) or [distance](https://radimrehurek.com/gensim/models/keyedvectors.html?highlight=distance#gensim.models.keyedvectors.KeyedVectors.distances) methods (an example is shown below)   \n",
    "2. Discuss your observations.\n",
    "\n",
    "> Note that most of the recent embeddings are de-biased. But you might still observe some biases in them. Also, not all stereotypes present in pre-trained embeddings are necessarily bad. But you should be aware of them when you use them in your models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of using analogy to explore biases and stereotypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(word1, word2, word3, model=glove_wiki_vectors):\n",
    "    \"\"\"\n",
    "    Returns analogy word using the given model.\n",
    "\n",
    "    Parameters\n",
    "    --------------\n",
    "    word1 : (str)\n",
    "        word1 in the analogy relation\n",
    "    word2 : (str)\n",
    "        word2 in the analogy relation\n",
    "    word3 : (str)\n",
    "        word3 in the analogy relation\n",
    "    model :\n",
    "        word embedding model\n",
    "\n",
    "    Returns\n",
    "    ---------------\n",
    "        pd.dataframe\n",
    "    \"\"\"\n",
    "    print(\"%s : %s :: %s : ?\" % (word1, word2, word3))\n",
    "    sim_words = model.most_similar(positive=[word3, word2], negative=[word1])\n",
    "    return pd.DataFrame(sim_words, columns=[\"Analogy word\", \"Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man : doctor :: woman : ?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analogy word</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nurse</td>\n",
       "      <td>0.773523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>physician</td>\n",
       "      <td>0.718943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doctors</td>\n",
       "      <td>0.682433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patient</td>\n",
       "      <td>0.675068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dentist</td>\n",
       "      <td>0.672603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pregnant</td>\n",
       "      <td>0.664246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>medical</td>\n",
       "      <td>0.652045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nursing</td>\n",
       "      <td>0.645348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mother</td>\n",
       "      <td>0.639333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hospital</td>\n",
       "      <td>0.638750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Analogy word     Score\n",
       "0        nurse  0.773523\n",
       "1    physician  0.718943\n",
       "2      doctors  0.682433\n",
       "3      patient  0.675068\n",
       "4      dentist  0.672603\n",
       "5     pregnant  0.664246\n",
       "6      medical  0.652045\n",
       "7      nursing  0.645348\n",
       "8       mother  0.639333\n",
       "9     hospital  0.638750"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy(\"man\", \"doctor\", \"woman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of using similarity between words to explore biases and stereotypes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.447236"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_wiki_vectors.similarity(\"white\", \"rich\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5174519"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_wiki_vectors.similarity(\"black\", \"rich\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4778229"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_wiki_vectors.similarity(\"man\", \"smart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36801586"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_wiki_vectors.similarity(\"woman\", \"smart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison 1\n",
    "- we can see that the similarity betweeen \"man\" and \"smart\" is much higher than between \"woman\" and \"smart\", highlighting a gender bias in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38604662"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_wiki_vectors.similarity(\"america\", \"evil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27105933"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_wiki_vectors.similarity(\"china\", \"evil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison 2\n",
    "- we can see that the similarity betweeen \"america\" and \"evil\" is much higher than between \"china\" and \"evil\", highlighting a nationaly-based bias in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3512528"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_wiki_vectors.similarity(\"black\", \"criminal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3492821"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_wiki_vectors.similarity(\"white\", \"criminal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black : criminal :: white : ?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analogy word</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prosecution</td>\n",
       "      <td>0.765332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>investigation</td>\n",
       "      <td>0.738572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indictment</td>\n",
       "      <td>0.711792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crimes</td>\n",
       "      <td>0.708782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>charges</td>\n",
       "      <td>0.705500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>prosecutors</td>\n",
       "      <td>0.697134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>investigations</td>\n",
       "      <td>0.696814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>case</td>\n",
       "      <td>0.679391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fbi</td>\n",
       "      <td>0.664048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>justice</td>\n",
       "      <td>0.664002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Analogy word     Score\n",
       "0     prosecution  0.765332\n",
       "1   investigation  0.738572\n",
       "2      indictment  0.711792\n",
       "3          crimes  0.708782\n",
       "4         charges  0.705500\n",
       "5     prosecutors  0.697134\n",
       "6  investigations  0.696814\n",
       "7            case  0.679391\n",
       "8             fbi  0.664048\n",
       "9         justice  0.664002"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy(\"black\", \"criminal\", \"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white : judge :: black : ?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analogy word</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>court</td>\n",
       "      <td>0.776896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>judges</td>\n",
       "      <td>0.742113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jury</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>supreme</td>\n",
       "      <td>0.685860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>appeals</td>\n",
       "      <td>0.680003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trial</td>\n",
       "      <td>0.634514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>verdict</td>\n",
       "      <td>0.633684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>appeal</td>\n",
       "      <td>0.631709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>defendant</td>\n",
       "      <td>0.629520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>attorney</td>\n",
       "      <td>0.628437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Analogy word     Score\n",
       "0        court  0.776896\n",
       "1       judges  0.742113\n",
       "2         jury  0.707071\n",
       "3      supreme  0.685860\n",
       "4      appeals  0.680003\n",
       "5        trial  0.634514\n",
       "6      verdict  0.633684\n",
       "7       appeal  0.631709\n",
       "8    defendant  0.629520\n",
       "9     attorney  0.628437"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy(\"white\", \"judge\", \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison 3\n",
    "- we can see that the similarity betweeen \"white\" and \"criminal\" is approximately the same as \"black\" and \"criminal\". Together with the results from the analogy methods, this indicates that there is likely a low level of bias when considering race and crime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fat : ugly :: skinny : ?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analogy word</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nasty</td>\n",
       "      <td>0.586500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cute</td>\n",
       "      <td>0.571785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>awkward</td>\n",
       "      <td>0.571268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adorable</td>\n",
       "      <td>0.554518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sexy</td>\n",
       "      <td>0.552583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gorgeous</td>\n",
       "      <td>0.547123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blond</td>\n",
       "      <td>0.543462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pointy</td>\n",
       "      <td>0.537222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gangly</td>\n",
       "      <td>0.530221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ragged</td>\n",
       "      <td>0.529547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Analogy word     Score\n",
       "0        nasty  0.586500\n",
       "1         cute  0.571785\n",
       "2      awkward  0.571268\n",
       "3     adorable  0.554518\n",
       "4         sexy  0.552583\n",
       "5     gorgeous  0.547123\n",
       "6        blond  0.543462\n",
       "7       pointy  0.537222\n",
       "8       gangly  0.530221\n",
       "9       ragged  0.529547"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy(\"fat\", \"ugly\", \"skinny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22042097"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_wiki_vectors.similarity(\"fat\", \"gross\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06481503"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_wiki_vectors.similarity(\"skinny\", \"gross\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3780058"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_wiki_vectors.similarity(\"fat\", \"pretty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49939656"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_wiki_vectors.similarity(\"skinny\", \"pretty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison 4\n",
    "- The similarity scores for \"fat\" vs \"skinny\" with the words \"gross\" and \"pretty\" display a clear fat phobia/ weight bias. The word \"fat\" gets a higher score in relation to \"gross\", and the word \"skinny\" has a high score in relation to \"pretty\". The analogy method further highlights this bias, with several of the analogy words being positive in relation to \"skinny\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity to the word 'stupid' : \n",
      "barista:  -0.10206677\n",
      "clerk:  0.13321412\n",
      "plumber:  0.21871105\n",
      "chef:  0.12953426\n",
      "waiter:  0.27270436\n",
      "teacher:  0.17423308\n",
      "pilot:  0.15247726\n",
      "lawyer:  0.1495709\n",
      "doctor:  0.21584412\n",
      "professor:  0.07812043\n",
      "accountant:  0.11629474\n"
     ]
    }
   ],
   "source": [
    "barista = glove_wiki_vectors.similarity(\"barista\", \"stupid\")\n",
    "clerk = glove_wiki_vectors.similarity(\"clerk\", \"stupid\")\n",
    "plumber = glove_wiki_vectors.similarity(\"plumber\", \"stupid\")\n",
    "chef = glove_wiki_vectors.similarity(\"chef\", \"stupid\")\n",
    "waiter = glove_wiki_vectors.similarity(\"waiter\", \"stupid\")\n",
    "teacher = glove_wiki_vectors.similarity(\"teacher\", \"stupid\")\n",
    "pilot = glove_wiki_vectors.similarity(\"pilot\", \"stupid\")\n",
    "lawyer = glove_wiki_vectors.similarity(\"lawyer\", \"stupid\")\n",
    "doctor = glove_wiki_vectors.similarity(\"doctor\", \"stupid\")\n",
    "prof = glove_wiki_vectors.similarity(\"professor\", \"stupid\")\n",
    "acc = glove_wiki_vectors.similarity(\"accountant\", \"stupid\")\n",
    "\n",
    "print(\"similarity to the word 'stupid' : \")\n",
    "print(\"barista: \", barista)\n",
    "print(\"clerk: \", clerk)\n",
    "print(\"plumber: \", plumber)\n",
    "print(\"chef: \", chef)\n",
    "print(\"waiter: \", waiter)\n",
    "print(\"teacher: \", teacher)\n",
    "print(\"pilot: \", pilot)\n",
    "print(\"lawyer: \", lawyer)\n",
    "print(\"doctor: \", doctor)\n",
    "print(\"professor: \", prof)\n",
    "print(\"accountant: \", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison 5\n",
    "- comparing a variety of job titles with the word \"stupid\", we see that there doesn't seem to be much consistent bias between intelligence and job title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.4 Discussion\n",
    "\n",
    "_Points:_ 4\n",
    "\n",
    "**Your tasks:**\n",
    "1. Based on your exploration above, comment on the overall quality of these pre-trained embeddings. \n",
    "2. In the lecture, we saw that our pre-trained word embedding model output an analogy that reinforced a gender stereotype. Give an example of how using such a model could cause harm in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.4\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. There seem to be some biases in the pre-trained embeddings as can be seen by the above analyses. Certain words are more heavily correlated with good or bad qualities, indicating biases in the data. However, its important to note that doing analysis such as these on single word pair comparisons may not provide the entire picture when it comes to bias in the data. As seen with Comparison 5 above, certain jobs are more correlated with the word \"stupid\" than others. If we had compared the similarity between \"stupid\" and \"plumber\" with the similarity between \"stupid\" and \"professor\", we may have assumed there was bias in the data, but taking a look at several examples shows that there isn't actually a consistent bias.\n",
    "\n",
    "2. Models like this can cause harm in the real world when their biases are used in ways which unequally harm different groups of people. Consider a university that uses such a model to quickly evaluate the hundreds of applications they receive. If certain countries are associated with good or bad qualities with regards to an individual's potential success at university, and this is used to filter applications out, it could  negatively impact certain groups of people. As seen below, Eygpt and Iran have relatively low scores for \"successful\" and Canada, Ireland, and Russia all have relatively low scores for \"smart\". If any of these relationships systematically discriminate against people from certain countries, this would cause real world harm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Similarity_Failure</th>\n",
       "      <th>Similarity_Smart</th>\n",
       "      <th>Similarity_Successful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>0.407563</td>\n",
       "      <td>0.269794</td>\n",
       "      <td>0.429247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India</td>\n",
       "      <td>0.332338</td>\n",
       "      <td>0.215138</td>\n",
       "      <td>0.384985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>0.328921</td>\n",
       "      <td>0.146819</td>\n",
       "      <td>0.381652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Russia</td>\n",
       "      <td>0.408797</td>\n",
       "      <td>0.145354</td>\n",
       "      <td>0.339599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>America</td>\n",
       "      <td>0.404370</td>\n",
       "      <td>0.349322</td>\n",
       "      <td>0.486080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Canada</td>\n",
       "      <td>0.280339</td>\n",
       "      <td>0.175802</td>\n",
       "      <td>0.402819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>0.336232</td>\n",
       "      <td>0.336232</td>\n",
       "      <td>0.293183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Iran</td>\n",
       "      <td>0.420348</td>\n",
       "      <td>0.420348</td>\n",
       "      <td>0.294948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country  Similarity_Failure  Similarity_Smart  Similarity_Successful\n",
       "0    China            0.407563          0.269794               0.429247\n",
       "1    India            0.332338          0.215138               0.384985\n",
       "2  Ireland            0.328921          0.146819               0.381652\n",
       "3   Russia            0.408797          0.145354               0.339599\n",
       "4  America            0.404370          0.349322               0.486080\n",
       "5   Canada            0.280339          0.175802               0.402819\n",
       "6    Egypt            0.336232          0.336232               0.293183\n",
       "7     Iran            0.420348          0.420348               0.294948"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinaf = glove_wiki_vectors.similarity(\"china\", \"failure\")\n",
    "indiaf = glove_wiki_vectors.similarity(\"india\", \"failure\")\n",
    "irelandf = glove_wiki_vectors.similarity(\"ireland\", \"failure\")\n",
    "russiaf = glove_wiki_vectors.similarity(\"russia\", \"failure\")\n",
    "americaf = glove_wiki_vectors.similarity(\"america\", \"failure\")\n",
    "canadaf = glove_wiki_vectors.similarity(\"canada\", \"failure\")\n",
    "egyptf = glove_wiki_vectors.similarity(\"egypt\", \"failure\")\n",
    "iranf = glove_wiki_vectors.similarity(\"iran\", \"failure\")\n",
    "\n",
    "chinas = glove_wiki_vectors.similarity(\"china\", \"smart\")\n",
    "indias = glove_wiki_vectors.similarity(\"india\", \"smart\")\n",
    "irelands = glove_wiki_vectors.similarity(\"ireland\", \"smart\")\n",
    "russias = glove_wiki_vectors.similarity(\"russia\", \"smart\")\n",
    "americas = glove_wiki_vectors.similarity(\"america\", \"smart\")\n",
    "canadas = glove_wiki_vectors.similarity(\"canada\", \"smart\")\n",
    "egypts = glove_wiki_vectors.similarity(\"egypt\", \"smart\")\n",
    "irans = glove_wiki_vectors.similarity(\"iran\", \"smart\")\n",
    "\n",
    "chinasu = glove_wiki_vectors.similarity(\"china\", \"successful\")\n",
    "indiasu = glove_wiki_vectors.similarity(\"india\", \"successful\")\n",
    "irelandsu = glove_wiki_vectors.similarity(\"ireland\", \"successful\")\n",
    "russiasu = glove_wiki_vectors.similarity(\"russia\", \"successful\")\n",
    "americasu = glove_wiki_vectors.similarity(\"america\", \"successful\")\n",
    "canadasu = glove_wiki_vectors.similarity(\"canada\", \"successful\")\n",
    "egyptsu = glove_wiki_vectors.similarity(\"egypt\", \"successful\")\n",
    "iransu = glove_wiki_vectors.similarity(\"iran\", \"successful\")\n",
    "\n",
    "similarity_scores = {\n",
    "    'Country': ['China', 'India', 'Ireland', 'Russia', 'America', 'Canada', 'Egypt', 'Iran'],\n",
    "    'Similarity_Failure': [chinaf, indiaf, irelandf, russiaf, americaf, canadaf, egyptf, iranf],\n",
    "    'Similarity_Smart': [chinas, indias, irelands, russias, americas, canadas, egyptf, iranf],\n",
    "    'Similarity_Successful': [chinasu, indiasu, irelandsu, russiasu, americasu, canadasu, egyptsu, iransu]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(similarity_scores)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 1.5 Classification with pre-trained embeddings \n",
    "\n",
    "_Points:_ 8\n",
    "\n",
    "In lecture 17, we saw that you can conveniently get word vectors with `spaCy` with `en_core_web_md` model. In this exercise, you'll use word embeddings in multi-class text classification task. We will use [HappyDB](https://www.kaggle.com/ritresearch/happydb) corpus which contains about 100,000 happy moments classified into 7 categories: *affection, exercise, bonding, nature, leisure, achievement, enjoy_the_moment*. The data was crowd-sourced via [Amazon Mechanical Turk](https://www.mturk.com/). The ground truth label is not available for all examples, and in this lab, we'll only use the examples where ground truth is available (~15,000 examples). \n",
    "\n",
    "- Download the data from [here](https://www.kaggle.com/ritresearch/happydb).\n",
    "- Unzip the file and copy it under the data/ directory in this homework directory.\n",
    "\n",
    "The code below reads the data CSV (assuming that it's present in the current directory as *cleaned_hm.csv*),  cleans it up a bit, and splits it into train and test splits. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Train logistic regression with bag-of-words features (`CountVectorizer`, be sure to filter out stop words), calculate the train and test accuracy and show a [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) on the test set.\n",
    "2. Train logistic regression with average embedding representation extracted using spaCy, calculate the train and test accuracy and show the [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>original_hm</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>modified</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>ground_truth_category</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27676</th>\n",
       "      <td>206</td>\n",
       "      <td>24h</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>bonding</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27678</th>\n",
       "      <td>45</td>\n",
       "      <td>24h</td>\n",
       "      <td>I meditated last night.</td>\n",
       "      <td>I meditated last night.</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>leisure</td>\n",
       "      <td>leisure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27697</th>\n",
       "      <td>498</td>\n",
       "      <td>24h</td>\n",
       "      <td>My grandmother start to walk from the bed afte...</td>\n",
       "      <td>My grandmother start to walk from the bed afte...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27705</th>\n",
       "      <td>5732</td>\n",
       "      <td>24h</td>\n",
       "      <td>I picked my daughter up from the airport and w...</td>\n",
       "      <td>I picked my daughter up from the airport and w...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>bonding</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27715</th>\n",
       "      <td>2272</td>\n",
       "      <td>24h</td>\n",
       "      <td>when i received flowers from my best friend</td>\n",
       "      <td>when i received flowers from my best friend</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>bonding</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        wid reflection_period  \\\n",
       "hmid                            \n",
       "27676   206               24h   \n",
       "27678    45               24h   \n",
       "27697   498               24h   \n",
       "27705  5732               24h   \n",
       "27715  2272               24h   \n",
       "\n",
       "                                             original_hm  \\\n",
       "hmid                                                       \n",
       "27676  We had a serious talk with some friends of our...   \n",
       "27678                            I meditated last night.   \n",
       "27697  My grandmother start to walk from the bed afte...   \n",
       "27705  I picked my daughter up from the airport and w...   \n",
       "27715        when i received flowers from my best friend   \n",
       "\n",
       "                                              cleaned_hm  modified  \\\n",
       "hmid                                                                 \n",
       "27676  We had a serious talk with some friends of our...      True   \n",
       "27678                            I meditated last night.      True   \n",
       "27697  My grandmother start to walk from the bed afte...      True   \n",
       "27705  I picked my daughter up from the airport and w...      True   \n",
       "27715        when i received flowers from my best friend      True   \n",
       "\n",
       "       num_sentence ground_truth_category predicted_category  \n",
       "hmid                                                          \n",
       "27676             2               bonding            bonding  \n",
       "27678             1               leisure            leisure  \n",
       "27697             1             affection          affection  \n",
       "27705             1               bonding          affection  \n",
       "27715             1               bonding            bonding  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/cleaned_hm.csv\", index_col=0)\n",
    "sample_df = df.dropna()\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = sample_df.rename(\n",
    "    columns={\"cleaned_hm\": \"moment\", \"ground_truth_category\": \"target\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(sample_df, test_size=0.3, random_state=123)\n",
    "X_train, y_train = train_df[\"moment\"], train_df[\"target\"]\n",
    "X_test, y_test = test_df[\"moment\"], test_df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need `spacy` to run the code below. If it's not in your course conda environment, you need to install it. \n",
    "\n",
    "> conda install -c conda-forge spacy\n",
    "\n",
    "You also need to download the following language model. \n",
    "\n",
    "> python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_md\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_md\")\n",
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.5\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.96\n",
      "test accuracy: 0.82\n",
      "classification report: \n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     achievement       0.79      0.87      0.83      1302\n",
      "       affection       0.90      0.91      0.91      1423\n",
      "         bonding       0.91      0.85      0.88       492\n",
      "enjoy_the_moment       0.60      0.54      0.57       469\n",
      "        exercise       0.91      0.57      0.70        74\n",
      "         leisure       0.73      0.70      0.71       407\n",
      "          nature       0.73      0.46      0.57        71\n",
      "\n",
      "        accuracy                           0.82      4238\n",
      "       macro avg       0.80      0.70      0.74      4238\n",
      "    weighted avg       0.82      0.82      0.81      4238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bow_train_accuracy = None\n",
    "bow_test_accuracy = None\n",
    "bow_report = None # use digits=2\n",
    "\n",
    "# max_iter was set to 1000 to avoid getting warning that the \"number of iterations reached limit\".\n",
    "pipe = make_pipeline(CountVectorizer(stop_words=\"english\"), LogisticRegression(max_iter=1000))\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "bow_train_accuracy = pipe.score(X_train, y_train)\n",
    "bow_test_accuracy = pipe.score(X_test, y_test)\n",
    "\n",
    "bow_pred = pipe.predict(X_test)\n",
    "bow_report = classification_report(y_test, bow_pred, digits=2)\n",
    "\n",
    "print(\"Train accuracy: %0.2f\" % bow_train_accuracy)\n",
    "print(\"Test accuracy: %0.2f\" % bow_test_accuracy) \n",
    "print(\"Classification report: \\n\", bow_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_embeddings = None\n",
    "X_test_embeddings = None\n",
    "\n",
    "# adapted from piazza @599_f1\n",
    "X_train_embeddings = pd.DataFrame([text.vector for text in nlp.pipe(X_train)])\n",
    "X_test_embeddings = pd.DataFrame([text.vector for text in nlp.pipe(X_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.690874</td>\n",
       "      <td>-0.755216</td>\n",
       "      <td>-3.279650</td>\n",
       "      <td>-1.111956</td>\n",
       "      <td>2.333812</td>\n",
       "      <td>1.712701</td>\n",
       "      <td>0.346985</td>\n",
       "      <td>5.052109</td>\n",
       "      <td>-1.078272</td>\n",
       "      <td>1.564646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978959</td>\n",
       "      <td>0.228331</td>\n",
       "      <td>0.843013</td>\n",
       "      <td>-1.340969</td>\n",
       "      <td>-0.884684</td>\n",
       "      <td>1.971317</td>\n",
       "      <td>-0.880458</td>\n",
       "      <td>-0.599687</td>\n",
       "      <td>-5.299727</td>\n",
       "      <td>-0.139515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021659</td>\n",
       "      <td>-1.051312</td>\n",
       "      <td>-4.063361</td>\n",
       "      <td>-1.818072</td>\n",
       "      <td>3.027572</td>\n",
       "      <td>-1.226410</td>\n",
       "      <td>0.035204</td>\n",
       "      <td>2.806751</td>\n",
       "      <td>-0.181556</td>\n",
       "      <td>1.530708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873182</td>\n",
       "      <td>-1.440154</td>\n",
       "      <td>0.219029</td>\n",
       "      <td>-1.426304</td>\n",
       "      <td>-1.591761</td>\n",
       "      <td>-0.475234</td>\n",
       "      <td>-0.122053</td>\n",
       "      <td>0.695197</td>\n",
       "      <td>-4.421231</td>\n",
       "      <td>-0.027261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.101639</td>\n",
       "      <td>-1.674547</td>\n",
       "      <td>-1.391433</td>\n",
       "      <td>-3.230565</td>\n",
       "      <td>0.636887</td>\n",
       "      <td>0.756545</td>\n",
       "      <td>0.205278</td>\n",
       "      <td>5.351284</td>\n",
       "      <td>-2.872737</td>\n",
       "      <td>3.033967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594443</td>\n",
       "      <td>0.435623</td>\n",
       "      <td>-0.556652</td>\n",
       "      <td>-2.759545</td>\n",
       "      <td>-1.521208</td>\n",
       "      <td>0.728254</td>\n",
       "      <td>-0.365033</td>\n",
       "      <td>1.230975</td>\n",
       "      <td>-5.989079</td>\n",
       "      <td>0.142662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.502830</td>\n",
       "      <td>-0.245505</td>\n",
       "      <td>-2.919757</td>\n",
       "      <td>-1.312146</td>\n",
       "      <td>3.315014</td>\n",
       "      <td>-0.281209</td>\n",
       "      <td>1.019417</td>\n",
       "      <td>3.909962</td>\n",
       "      <td>-0.440415</td>\n",
       "      <td>0.797455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452126</td>\n",
       "      <td>-0.261931</td>\n",
       "      <td>-0.375499</td>\n",
       "      <td>-0.218783</td>\n",
       "      <td>-1.355882</td>\n",
       "      <td>0.384430</td>\n",
       "      <td>0.619531</td>\n",
       "      <td>0.548577</td>\n",
       "      <td>-3.217188</td>\n",
       "      <td>0.119259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.503838</td>\n",
       "      <td>-0.450076</td>\n",
       "      <td>-4.626111</td>\n",
       "      <td>-2.820389</td>\n",
       "      <td>4.793096</td>\n",
       "      <td>-0.805586</td>\n",
       "      <td>1.518527</td>\n",
       "      <td>5.712772</td>\n",
       "      <td>1.548753</td>\n",
       "      <td>1.589522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.293538</td>\n",
       "      <td>-0.217686</td>\n",
       "      <td>-3.700689</td>\n",
       "      <td>-1.188137</td>\n",
       "      <td>0.648456</td>\n",
       "      <td>-2.548641</td>\n",
       "      <td>-0.413536</td>\n",
       "      <td>1.096762</td>\n",
       "      <td>-3.927443</td>\n",
       "      <td>-1.008204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.690874 -0.755216 -3.279650 -1.111956  2.333812  1.712701  0.346985   \n",
       "1  0.021659 -1.051312 -4.063361 -1.818072  3.027572 -1.226410  0.035204   \n",
       "2 -0.101639 -1.674547 -1.391433 -3.230565  0.636887  0.756545  0.205278   \n",
       "3 -1.502830 -0.245505 -2.919757 -1.312146  3.315014 -0.281209  1.019417   \n",
       "4 -0.503838 -0.450076 -4.626111 -2.820389  4.793096 -0.805586  1.518527   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0  5.052109 -1.078272  1.564646  ...  0.978959  0.228331  0.843013 -1.340969   \n",
       "1  2.806751 -0.181556  1.530708  ...  0.873182 -1.440154  0.219029 -1.426304   \n",
       "2  5.351284 -2.872737  3.033967  ...  0.594443  0.435623 -0.556652 -2.759545   \n",
       "3  3.909962 -0.440415  0.797455  ...  0.452126 -0.261931 -0.375499 -0.218783   \n",
       "4  5.712772  1.548753  1.589522  ... -0.293538 -0.217686 -3.700689 -1.188137   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0 -0.884684  1.971317 -0.880458 -0.599687 -5.299727 -0.139515  \n",
       "1 -1.591761 -0.475234 -0.122053  0.695197 -4.421231 -0.027261  \n",
       "2 -1.521208  0.728254 -0.365033  1.230975 -5.989079  0.142662  \n",
       "3 -1.355882  0.384430  0.619531  0.548577 -3.217188  0.119259  \n",
       "4  0.648456 -2.548641 -0.413536  1.096762 -3.927443 -1.008204  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.958416</td>\n",
       "      <td>3.125293</td>\n",
       "      <td>-4.034988</td>\n",
       "      <td>-2.041907</td>\n",
       "      <td>2.595106</td>\n",
       "      <td>0.445679</td>\n",
       "      <td>0.386465</td>\n",
       "      <td>5.083802</td>\n",
       "      <td>-1.852383</td>\n",
       "      <td>1.560549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379911</td>\n",
       "      <td>-0.726037</td>\n",
       "      <td>-1.127668</td>\n",
       "      <td>-0.563859</td>\n",
       "      <td>0.177253</td>\n",
       "      <td>-0.294613</td>\n",
       "      <td>-0.855359</td>\n",
       "      <td>1.358393</td>\n",
       "      <td>-7.270348</td>\n",
       "      <td>1.399086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.299894</td>\n",
       "      <td>0.630366</td>\n",
       "      <td>-2.318005</td>\n",
       "      <td>-2.507104</td>\n",
       "      <td>4.050345</td>\n",
       "      <td>-0.310809</td>\n",
       "      <td>0.272773</td>\n",
       "      <td>3.979269</td>\n",
       "      <td>1.976808</td>\n",
       "      <td>0.731067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931720</td>\n",
       "      <td>0.025334</td>\n",
       "      <td>-0.485929</td>\n",
       "      <td>-0.743087</td>\n",
       "      <td>-1.798334</td>\n",
       "      <td>2.132924</td>\n",
       "      <td>0.299637</td>\n",
       "      <td>0.670521</td>\n",
       "      <td>-3.445617</td>\n",
       "      <td>0.822201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.671838</td>\n",
       "      <td>-3.753560</td>\n",
       "      <td>-2.243932</td>\n",
       "      <td>-6.034901</td>\n",
       "      <td>-2.993384</td>\n",
       "      <td>2.103476</td>\n",
       "      <td>-0.182704</td>\n",
       "      <td>1.314220</td>\n",
       "      <td>0.393286</td>\n",
       "      <td>0.491056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021817</td>\n",
       "      <td>0.214875</td>\n",
       "      <td>-1.920058</td>\n",
       "      <td>-0.585280</td>\n",
       "      <td>-2.042112</td>\n",
       "      <td>1.066200</td>\n",
       "      <td>-0.503640</td>\n",
       "      <td>0.496954</td>\n",
       "      <td>-0.952958</td>\n",
       "      <td>-0.096886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.285316</td>\n",
       "      <td>-1.347252</td>\n",
       "      <td>-5.520160</td>\n",
       "      <td>-1.793326</td>\n",
       "      <td>-0.319224</td>\n",
       "      <td>-4.395940</td>\n",
       "      <td>-0.787140</td>\n",
       "      <td>3.501826</td>\n",
       "      <td>-2.966559</td>\n",
       "      <td>4.460822</td>\n",
       "      <td>...</td>\n",
       "      <td>2.226200</td>\n",
       "      <td>-1.617096</td>\n",
       "      <td>1.458074</td>\n",
       "      <td>-4.914721</td>\n",
       "      <td>-2.545942</td>\n",
       "      <td>-3.723066</td>\n",
       "      <td>-2.130358</td>\n",
       "      <td>1.875884</td>\n",
       "      <td>-8.811860</td>\n",
       "      <td>-0.704100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.296173</td>\n",
       "      <td>1.518396</td>\n",
       "      <td>-3.726718</td>\n",
       "      <td>-1.118125</td>\n",
       "      <td>1.690331</td>\n",
       "      <td>-1.578362</td>\n",
       "      <td>0.601601</td>\n",
       "      <td>5.086967</td>\n",
       "      <td>-0.884238</td>\n",
       "      <td>3.076164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435902</td>\n",
       "      <td>0.211110</td>\n",
       "      <td>1.393579</td>\n",
       "      <td>0.039486</td>\n",
       "      <td>-2.776130</td>\n",
       "      <td>1.652559</td>\n",
       "      <td>3.089273</td>\n",
       "      <td>2.418594</td>\n",
       "      <td>-3.963638</td>\n",
       "      <td>0.478087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.958416  3.125293 -4.034988 -2.041907  2.595106  0.445679  0.386465   \n",
       "1 -1.299894  0.630366 -2.318005 -2.507104  4.050345 -0.310809  0.272773   \n",
       "2  1.671838 -3.753560 -2.243932 -6.034901 -2.993384  2.103476 -0.182704   \n",
       "3  3.285316 -1.347252 -5.520160 -1.793326 -0.319224 -4.395940 -0.787140   \n",
       "4 -3.296173  1.518396 -3.726718 -1.118125  1.690331 -1.578362  0.601601   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0  5.083802 -1.852383  1.560549  ... -0.379911 -0.726037 -1.127668 -0.563859   \n",
       "1  3.979269  1.976808  0.731067  ...  0.931720  0.025334 -0.485929 -0.743087   \n",
       "2  1.314220  0.393286  0.491056  ... -0.021817  0.214875 -1.920058 -0.585280   \n",
       "3  3.501826 -2.966559  4.460822  ...  2.226200 -1.617096  1.458074 -4.914721   \n",
       "4  5.086967 -0.884238  3.076164  ...  0.435902  0.211110  1.393579  0.039486   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0  0.177253 -0.294613 -0.855359  1.358393 -7.270348  1.399086  \n",
       "1 -1.798334  2.132924  0.299637  0.670521 -3.445617  0.822201  \n",
       "2 -2.042112  1.066200 -0.503640  0.496954 -0.952958 -0.096886  \n",
       "3 -2.545942 -3.723066 -2.130358  1.875884 -8.811860 -0.704100  \n",
       "4 -2.776130  1.652559  3.089273  2.418594 -3.963638  0.478087  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy with embeddings: 0.85\n",
      "Test accuracy with embeddings: 0.79\n",
      "Classification report with embeddings:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     achievement       0.81      0.83      0.82      1302\n",
      "       affection       0.86      0.91      0.89      1423\n",
      "         bonding       0.83      0.77      0.80       492\n",
      "enjoy_the_moment       0.57      0.51      0.53       469\n",
      "        exercise       0.68      0.76      0.72        74\n",
      "         leisure       0.72      0.65      0.68       407\n",
      "          nature       0.68      0.72      0.70        71\n",
      "\n",
      "        accuracy                           0.79      4238\n",
      "       macro avg       0.74      0.74      0.73      4238\n",
      "    weighted avg       0.79      0.79      0.79      4238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emb_train_accuracy = None\n",
    "emb_test_accuracy = None\n",
    "emb_report = None # use digits=2\n",
    "\n",
    "# max_iter was set to 10000 to avoid getting warning that the \"number of iterations reached limit\".\n",
    "emb_pipe = make_pipeline(LogisticRegression(max_iter=10000))\n",
    "emb_pipe.fit(X_train_embeddings, y_train)\n",
    "\n",
    "\n",
    "emb_train_accuracy = emb_pipe.score(X_train_embeddings, y_train)\n",
    "emb_test_accuracy = emb_pipe.score(X_test_embeddings, y_test)\n",
    "\n",
    "emb_pred = emb_pipe.predict(X_test_embeddings)\n",
    "emb_report = classification_report(y_test, emb_pred, digits=2)\n",
    "\n",
    "\n",
    "print(\"Train accuracy with embeddings: %.2f\" % emb_train_accuracy)\n",
    "print(\"Test accuracy with embeddings: %.2f\" % emb_test_accuracy)\n",
    "print(\"Classification report with embeddings:\\n\", emb_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.6 Discussion\n",
    "\n",
    "_Points:_ 6\n",
    "\n",
    "**Your tasks:**\n",
    "1. Briefly explain the difference between using `CountVectorizer` vs. average-embedding approach for text classification.  \n",
    "2. Which representation among these two would be more interpretable? Why?   \n",
    "3. Are we using any transfer learning here? If yes, are you observing any benefits of transfer learning? Briefly discuss. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.6\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. CountVectorizer counts the number of occurances of each word in the provided text, representing the frequency of that word in the data. Word order and context are not considered when using CountVectorizer. The average-embeddings approach captures semantic contextual information for each word in addition to frequency counts based on that word's embeddings. \n",
    "\n",
    "2. With both methods, we are able to examine the report to get a general understanding of how both method performed. However, CountVectorizer is easier to interpret because it is a simplified analysis in comparison to using average-embeddings. With CountVectorizer, we can easily see which words contribute more or less to classification decisions since each feature corresponds to a single unique word in the data set. This information is more obscured and complex when we use average-embeddings because context is included in the analysis.\n",
    "\n",
    "3. We are using transfer learning because we are leveraging spaCy's pre-trained word embeddings. We are seeing the benefits here because we aren't having to train our model on a huge data set. Since we are able to utilize spaCy's pre-training word embeddings, our model can leverage the knowledge learned from this large data set and potentially capture more nuanced semantic relationships that may have otherwise been missed if we had simply trained out model on our relatively small single dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Topic modeling \n",
    "\n",
    "The overarching goal of topic modeling is understanding high-level themes in a large collection of texts in an unsupervised way. \n",
    "\n",
    "In this exercise you will explore topics in a subset of `scikit-learn`'s [20 newsgroups text dataset](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) using `scikit-learn`'s `LatentDirichletAllocation` (LDA) model. \n",
    "\n",
    "Usually, topic modeling is used for discovering abstract \"topics\" that occur in a collection of documents when you do not know the actual topics present in the documents. But 20 newsgroups text dataset is labeled with categories (e.g., sports, hardware, religion), and you will be able to cross-check the topics discovered by your model with these available topics. \n",
    "\n",
    "The starter code below loads the train and test portion of the data and convert the train portion into a pandas DataFrame. For speed, we will only consider documents with the following 8 categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>target_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You know, I was reading 18 U.S.C. 922 and some...</td>\n",
       "      <td>6</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\nIt's not a bad question: I don't have an...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nActuallay I don't, but on the other hand I d...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The following problem is really bugging me,\\na...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.windows.x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n  This is the latest from UPI \\n\\n     For...</td>\n",
       "      <td>7</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4558</th>\n",
       "      <td>Hi Everyone ::\\n\\nI am  looking for  some soft...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>Archive-name: x-faq/part3\\nLast-modified: 1993...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.windows.x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4560</th>\n",
       "      <td>\\nThat's nice, but it doesn't answer the quest...</td>\n",
       "      <td>6</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>Hi,\\n     I just got myself a Gateway 4DX-33V ...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.windows.x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>\\n\\n[h] \\tThe Armenians in Nagarno-Karabagh ar...</td>\n",
       "      <td>7</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4563 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target  \\\n",
       "0     You know, I was reading 18 U.S.C. 922 and some...       6   \n",
       "1     \\n\\n\\nIt's not a bad question: I don't have an...       1   \n",
       "2     \\nActuallay I don't, but on the other hand I d...       1   \n",
       "3     The following problem is really bugging me,\\na...       2   \n",
       "4     \\n\\n  This is the latest from UPI \\n\\n     For...       7   \n",
       "...                                                 ...     ...   \n",
       "4558  Hi Everyone ::\\n\\nI am  looking for  some soft...       1   \n",
       "4559  Archive-name: x-faq/part3\\nLast-modified: 1993...       2   \n",
       "4560  \\nThat's nice, but it doesn't answer the quest...       6   \n",
       "4561  Hi,\\n     I just got myself a Gateway 4DX-33V ...       2   \n",
       "4562  \\n\\n[h] \\tThe Armenians in Nagarno-Karabagh ar...       7   \n",
       "\n",
       "                target_name  \n",
       "0        talk.politics.guns  \n",
       "1             comp.graphics  \n",
       "2             comp.graphics  \n",
       "3            comp.windows.x  \n",
       "4     talk.politics.mideast  \n",
       "...                     ...  \n",
       "4558          comp.graphics  \n",
       "4559         comp.windows.x  \n",
       "4560     talk.politics.guns  \n",
       "4561         comp.windows.x  \n",
       "4562  talk.politics.mideast  \n",
       "\n",
       "[4563 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = [\n",
    "    \"rec.sport.hockey\",\n",
    "    \"rec.sport.baseball\",\n",
    "    \"soc.religion.christian\",\n",
    "    \"alt.atheism\",\n",
    "    \"comp.graphics\",\n",
    "    \"comp.windows.x\",\n",
    "    \"talk.politics.mideast\",\n",
    "    \"talk.politics.guns\",\n",
    "]  # We'll only consider these categories out of 20 categories for speed.\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(\n",
    "    subset=\"train\", remove=(\"headers\", \"footers\", \"quotes\"), categories=cats\n",
    ")\n",
    "X_news_train, y_news_train = newsgroups_train.data, newsgroups_train.target\n",
    "df = pd.DataFrame(X_news_train, columns=[\"text\"])\n",
    "df[\"target\"] = y_news_train\n",
    "df[\"target_name\"] = [\n",
    "    newsgroups_train.target_names[target] for target in newsgroups_train.target\n",
    "]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.windows.x',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.1 Preprocessing using [spaCy](https://spacy.io/)\n",
    "\n",
    "_Points:_ 8\n",
    "\n",
    "In this exercise you'll prepare the data for topic modeling using [spaCy](https://spacy.io/). Preprocessing is a crucial step before training an LDA model and it markedly affects topic modeling results. So let's carry out preprocessing. \n",
    "\n",
    "**Your tasks:** \n",
    "\n",
    "Write code to carry out preprocessing of the \"text\" column in the dataframe above and store the preprocessed text in a new column called \"text_pp\" in the dataframe. \n",
    "\n",
    "\n",
    "Note that there is no such thing as \"perfect\" preprocessing. You'll have to make your own judgments and decisions on which tokens are more informative and which ones are less informative for the given task. Some common text preprocessing steps for topic modeling are: \n",
    "- getting rid of slashes or other weird characters\n",
    "- sentence segmentation and tokenization      \n",
    "- getting rid of urls and email addresses\n",
    "- getting rid of other fairly unique tokens which are not going to help us in topic modeling  \n",
    "- excluding stopwords and punctuation \n",
    "- lemmatization        \n",
    "\n",
    "You might have to go back and forth between the preprocessing and topic modeling and interpretation steps in the next exercises. \n",
    "\n",
    "> Check out [these available attributes](https://spacy.io/api/token#attributes) for `token` in spaCy which might help you with preprocessing. \n",
    "\n",
    "> You can also get rid of words with specific POS tags. [Here](https://spacy.io/api/annotation/#pos-en) is the list of part-of-speech tags used in spaCy. \n",
    "\n",
    "> Note that preprocessing the corpus might take some time. So here are a couple of suggestions: 1) During the debugging phase, work on a smaller subset of the data. 2) Once you're done with the preprocessing part, you might want to save the preprocessed data so that you don't run the preprocessing part every time you run the notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    preprocessed_text = [token.text.lower() for token in doc]\n",
    "\n",
    "    # Remove stopwords, punctuation, and short words\n",
    "    preprocessed_text = [token for token in preprocessed_text if token not in nlp.Defaults.stop_words and len(token) > 2 and token.isalpha()]\n",
    "   \n",
    "    # Remove numerical values\n",
    "    preprocessed_text = [token for token in preprocessed_text if not token.isdigit()]\n",
    "    \n",
    "    # Remove non-alphanumeric characters\n",
    "    preprocessed_text = [token for token in preprocessed_text if token.isalnum()]\n",
    "    \n",
    "    # Lemmatize\n",
    "    preprocessed_text = [token.lemma_ for token in nlp(' '.join(preprocessed_text))]\n",
    "    \n",
    "    # Join the tokens back into a single string\n",
    "    preprocessed_text = ' '.join(preprocessed_text)\n",
    "\n",
    "    return preprocessed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>target_name</th>\n",
       "      <th>text_pp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You know, I was reading 18 U.S.C. 922 and some...</td>\n",
       "      <td>6</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "      <td>know read sence wonder help provide paragraph ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\nIt's not a bad question: I don't have an...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>bad question ref list algorithm think bit hard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nActuallay I don't, but on the other hand I d...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>actuallay hand support idea have newsgroup asp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The following problem is really bugging me,\\na...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.windows.x</td>\n",
       "      <td>follow problem bug appreciate help create wind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n  This is the latest from UPI \\n\\n     For...</td>\n",
       "      <td>7</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>late upi foreign ministry spokesman ferhat ata...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  You know, I was reading 18 U.S.C. 922 and some...       6   \n",
       "1  \\n\\n\\nIt's not a bad question: I don't have an...       1   \n",
       "2  \\nActuallay I don't, but on the other hand I d...       1   \n",
       "3  The following problem is really bugging me,\\na...       2   \n",
       "4  \\n\\n  This is the latest from UPI \\n\\n     For...       7   \n",
       "\n",
       "             target_name                                            text_pp  \n",
       "0     talk.politics.guns  know read sence wonder help provide paragraph ...  \n",
       "1          comp.graphics  bad question ref list algorithm think bit hard...  \n",
       "2          comp.graphics  actuallay hand support idea have newsgroup asp...  \n",
       "3         comp.windows.x  follow problem bug appreciate help create wind...  \n",
       "4  talk.politics.mideast  late upi foreign ministry spokesman ferhat ata...  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_pp'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.2 Justification\n",
    "\n",
    "_Points:_ 2\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Outline the preprocessing steps you carried out in the previous exercise and provide a brief justification for these steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2_2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Text was tokenized to split it into individual tokens to allow for further processing.\n",
    "2. The text was converted to lowercase to ensure consistency and prevent duplication of words due to different cases. This helps reduce dimensionality in the data.\n",
    "3. Stopwords, punctuation, and short words were removed from the text because they don't typically contribute to the semantic meaning of the text.\n",
    "4. Numberical values were removed because these are generally unimportant for topic modelling.\n",
    "5. Non-alphanumeric characters were removed because these also typically do not contribute to the semantic meaning of the text.\n",
    "6. Tokens were lemmatized to normalize the text by converting words to their base form. This allows words like \"cars\" and \"car\" to be treated semantically identically while also reducing the dimensionality of the data.\n",
    "7. The tokens were joined back together into a single string so they could be added back into the df and be used in further modelling and analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.3 Build a topic model using sklearn's LatentDirichletAllocation\n",
    "\n",
    "_Points:_ 4\n",
    "\n",
    "**Your tasks:**\n",
    "1. Create a topic model on the preprocessed data using [sklearn's `LatentDirichletAllocation`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html). Pick a reasonable number for `n_components`, i.e., number of topics and briefly justify your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2_3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 general categories in our topics: religion, sports, politics, technology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "n_topics = 4\n",
    "\n",
    "vec = CountVectorizer(stop_words='english')\n",
    "text_fit_trans = vec.fit_transform(df[\"text_pp\"])\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "lda.fit(text_fit_trans)\n",
    "\n",
    "topics = lda.transform(text_fit_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.4 Exploring word topic association\n",
    "\n",
    "_Points:_ 5\n",
    "\n",
    "**Your tasks:**\n",
    "1. Show top 10 words for each of your topics and suggest labels for each of the topics (similar to how we came up with labels \"health and nutrition\", \"fashion\", and \"machine learning\" in the toy example we saw in class). \n",
    "\n",
    "> If your topics do not make much sense, you might have to go back to preprocessing in Exercise 2.1, improve it, and train your LDA model again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2_4\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "file, program, use, image, window, include, available, server, run, work\n",
      "\n",
      "Topic 1:\n",
      "game, team, year, play, good, player, win, season, think, time\n",
      "\n",
      "Topic 2:\n",
      "people, armenian, gun, right, state, israel, turkish, government, jews, kill\n",
      "\n",
      "Topic 3:\n",
      "god, people, say, know, think, come, believe, time, thing, like\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_names = vec.get_feature_names_out()\n",
    "n_top_words = 10  \n",
    "\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic {topic_idx}:\")\n",
    "    top_words_indices = topic.argsort()[:-n_top_words - 1:-1]\n",
    "    top_words = [feature_names[i] for i in top_words_indices]\n",
    "    print(\", \".join(top_words))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggested topic labels:\n",
    "- 0 : Computers and Software\n",
    "- 1 : Sports\n",
    "- 2 : Political Conflict\n",
    "- 3 : Religion and Philosophy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.5 Exploring document topic association\n",
    "\n",
    "_Points:_ 5\n",
    "\n",
    "**Your tasks:**\n",
    "1. Show the document topic assignment of the first five documents from `df`. \n",
    "2. Comment on the document topic assignment of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2_5\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Exercise 3: Short answer questions \n",
    "<hr>\n",
    "\n",
    "_Points:_ 6\n",
    "\n",
    "1. In lecture 18, we talked about multi-class classification. Comment on how each model in the list below might be handling multiclass classification. Check `scikit-learn` documentation for each of these models when you answer this question.  \n",
    "    - Decision Tree\n",
    "    - KNN\n",
    "    - Random Forest    \n",
    "    - Logistic Regression\n",
    "    - SVM RBF\n",
    "2. What is transfer learning in natural language processing or computer vision? Briefly explain.     \n",
    "3. In Lecture 18 we briefly discussed how neural networks are sort of like `Pipeline`s, in the sense that they involve multiple sequential transformations of the data, finally resulting in the prediction. Why was this property useful when it came to transfer learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PLEASE READ BEFORE YOU SUBMIT:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from 1 will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using [PrairieLearn](https://ca.prairielearn.com/pl/course_instance/6697). Don't forget to rename your file `hw6_sol.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/eva-well-done.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc330",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
